---
title: "Complete data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Complete_data}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

#To build all vignettes properly, run devtools::build_vignettes(), not devtools::build_rmd("vignettes/Complete_data.Rmd"). This command ensures all vignettes are compiled correctly and links are processed within the package context.
```

It is instructive to see how the item-level models and approaches can yield the same results as when the model is fit directly to the composites, when there is no missing data. 

We will use the built-in dataset `tpbdata`, which does not contain any missing values. This dataset was collected to test the theory of planned behavior, and contains 11 Attitudes items, 3 Perceived Behavioral Control (PBC) items, 3 Norms items, 3 Intention items, and 1 measure of Behavior; for more information, see `help(tpbdata)`. 

In the syntax below, we first create a new dataset that contains only the composites: 

```{r tpbdatac}
library(twostage)

tpbdatac<-data.frame(matrix(ncol = 0, nrow = nrow(tpbdata))) #new data frame
at_names <- grep("AT", names(tpbdata), value = TRUE) #names of 11 attitude items
tpbdatac$ATTALL<-rowSums(tpbdata[at_names]) #new variable that is sum of 11 attitude items
tpbdatac$PBCALL<-rowSums(tpbdata[c("PBC1","PBC2","PBC3")]) #new variable that is sum of 3 PBC items
tpbdatac$NORSALL<-rowSums(tpbdata[c("NORS1","NORS2","NORS3")]) #new variable that is sum of 3 NORS items
tpbdatac$INTALL<-rowSums(tpbdata[c("INT1","INT2","INT3")]) #new variable that is sum of 3 INT items
tpbdatac$BEH<-rowSums(tpbdata["BEH"]) #BEH variable copied from the original dataset
```

We then specify the composite-level model, which hypothesizes full mediation: 

```{r tpbmod}
#composite-level model (BEH stays as as single indicator variable)
tpbmod<-'
INTALL ~ ATTALL + PBCALL + NORSALL
BEH ~ INTALL'
```

We then fit it directly to the composites in `lavaan`: 
```{r comp}
fit_comp<-lavaan::sem(tpbmod,data=tpbdatac,fixed.x=FALSE,meanstructure=TRUE)
fit_comp
est_comp<-lavaan::parameterestimates(fit_comp,ci=FALSE) #parameter estimates
est_comp

```
The printed chi-square, df, parameter estimates, and standard errors from `fit_comp` will be the values to match by the item-level methods, which will fit the same model `tpbmod` to the original dataset `tpbdata` containing only the items, without computing the composites explicitly. 

We first need to define the matrix $C$ that relates composites to components. The end user can assign components to composites interactively as follows:

``` 
C <- stage0(data=tpbdata,model=tpbmod)
```
For this vignette, we specify this matrix manually: 

```{r C}
cnames<-lavaan::lavNames(tpbmod)
C <- matrix(0,nrow=length(cnames),ncol=length(colnames(tpbdata)))
colnames(C)<-colnames(tpbdata)
rownames(C)<-cnames
C[1,c("INT1","INT2","INT3")]<-1
C[2,c("BEH")]<-1
C[3,grep("AT", names(tpbdata))]<-1
C[4,c("PBC1","PBC2","PBC3")]<-1
C[5,c("NORS1","NORS2","NORS3")]<-1
C
```

### TSML 

To match the complete data analysis when using TSML, we have to specify expected rather than observed information for Stage 1 (via `runcommand`), and skip the default rescaling of the input covariance matrix in Stage 2 (via `runcommand2`).   

```{r TSML1}
fit_ts <- twostage(data = tpbdata, compmodel = tpbmod, C = C,
runcommand = "information='expected'", runcommand2 = "sample.cov.rescale=FALSE")
```

The summary output shows the TS parameter estimates, the "naive" standard errors from Stage 2, which assume the input summary statistics into Stage 2 were obtained from complete data, and the TSML standard errors, which adjust for the uncertainty due to missing data: 

```{r TSML2}
summary(fit_ts) 
```

Because the data are complete and we have matched the type of information with what is used by default with complete data, the corrections in the "TSML" standard error formula "cancel out", and the "naive" and "TSML" standard errors are identical to all stored decimal places.  

Estimates and standard errors from `fit_comp` and `fit_ts` are also essentially identical. Below is their comparison side by side:  

```{r comp_vs_ts1}
comp_table <- compare_est(fit_comp,fit_ts)
comp_table
```

The naive chi-square is identical to the chi-square from `fit_comp`: 

```{r comp_vs_ts3}
lavaan::fitmeasures(fit_ts)[c("chisq","df","pvalue")] 
```

The residual-based TSML chi-square produces a slightly different value from the naive chi-square:

```{r comp_vs_ts4}
summary_ts <- summary(fit_ts) 
unlist(summary_ts[c("Tres", "df", "pval")])
```

Because it is computed as a quadratic form, and does not use the ML fit function equation, it will be highly similar, but not numerically identical to the "naive" ML chi-square even when the data are complete. (Note: In the original papers on the residual-based chi-square with item-level missing data, $N-1$ was used as a sample size multiplier, but $N$ is used in the `twostage` code for consistency with `lavaan` defaults for all other statistics.)

<!-- commented out GLS because it looks like the GLS chi-square is N*2*fmin, but it matches ts if we multiply it by N/(N-1)...  
Instead, it will be closer to the chi-square from the GLS method: 

```{r gls, eval=FALSE}
fit_comp_gls<-lavaan::sem(tpbmod,data=tpbdatac,fixed.x=FALSE,
                          meanstructure=TRUE,estimator="GLS") 
lavaan::fitmeasures(fit_comp_gls)[c("fmin","chisq","df","pvalue")] 
N <- lavInspect(fit_comp_gls, "nobs")
#GLS chi-square:
gls_chisq <- 0.03215490*2*108 #fmin*2*N
#TS res-based chi-square:
ts_chisq <- gls_chisq*108/(108-1) #gls_chisq *N/(N-1), almost

```
When the model is correct, both GLS and ML are asymptotically fully efficient, and they are also asymptotically equivalent. --> 


### PIM

The PIM model syntax sets up each composite as a special latent variable, with the structure on the observed variables such that the latent variable turns out to be equal to the observed composite. The composites model is then embedded within the larger PIM model. We obtain the `lavaan` syntax for PIM as follows: 
```{r PIM1}
tpbpim <- PIM_syntax(compmodel=tpbmod,C=C)
#cat(tpbpim)
```

We then fit this model in `lavaan` (without declaring missing data):

```{r PIM2}
fit_pim <- lavaan::lavaan(tpbpim, data=tpbdata)
fit_pim
est_pim<-lavaan::parameterestimates(fit_pim,ci=FALSE) 
```
While the `sem` function also works here, it is best to use the `lavaan` function for PIM models to avoid any unintended defaults. The test statistic value and df are identical to `fit_comp`, even though the number of model parameters is much higher (`r lavaan::fitmeasures(fit_pim)["npar"]`), because the items are also in the model (but in a saturated form).  

The parameter estimates and standard errors for the relevant parameters are essentially identical to those from the `fit_comp` run: 

```{r PIM3}
comp_table <- compare_est(fit_comp,fit_pim)[,c("est.fit_comp","se.fit_comp","est.fit_pim","se.fit_pim")]
comp_table
```

Lastly, fit measures from the model fit directly to the composites (`fit_comp`) and the "naive" fit measures from Stage 2 of TSML (`fit_ts`) are the same. (This will not be the case with incomplete data). The PIM fit measures (`fit_pim`) that are expected to be the same, such as chi-square and RMSEA, are the same as TSML. 

```{r afi1}
afi_comp <- lavaan::fitmeasures(fit_comp)
afi_ts_naive <- lavaan::fitmeasures(fit_ts) 
afi_pim <- lavaan::fitmeasures(fit_pim)
round(cbind(afi_comp,afi_ts_naive,afi_pim),3)
```

Indices depending on the baseline model (e.g., CFI) and those depending on the residuals (e.g., SRMR) are different for PIM, and the default printed values are not optimal. Instead, CFI should be computed using a different baseline model for a better evaluation of the fit of just the composite model in the PIM setup. SRMR should be computed comparing only the residuals for the variables in the composite model. Both of these modifications have been proposed in [Rose, Wagner, Mayer, and Nagengast (2019)](https://online.ucpress.edu/collabra/article/5/1/9/112958/Model-Based-Manifest-and-Latent-Composite-Scores). See [Approximate_fit vignette](../doc/Approximate_fit.html) for more detail. Here, we just show how to obtain these adjusted CFI and SRMR values: 

```{r afi2}
fitm_pim <- fitMeasures_pim(C, compmodel=tpbmod, fit_pim=fit_pim, data = tpbdata, exog_cov = TRUE)
fitm_pim[c("cfi","srmr")]

afi_comp <- lavaan::fitmeasures(fit_comp)[c("cfi","srmr")]
afi_comp
```
They are identical to the corresponding CFI and SRMR run for the complete data run `fit_comp`. We note that information criteria (e.g., AIC, BIC) will be different for PIM but these do not require corrections. These indices are used for model comparison and do not have interpretable values in isolation. As long as all models being compared are fit using the same methodology (e.g., PIM, twostage, complete data, etc), information indices can be used to select among models. 
